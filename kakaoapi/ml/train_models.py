import pandas as pd
import joblib
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from lightgbm import LGBMClassifier
from sklearn.model_selection import GroupShuffleSplit
from sklearn.metrics import mean_absolute_error, accuracy_score
from sklearn.utils import resample
import seaborn as sns
import matplotlib.pyplot as plt
from kakaoapi.models import RunHistory
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split

import os

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_DIR = os.path.join(BASE_DIR, 'models')

def convert_elapsed_to_min(s):
    """
    ë¬¸ìì—´ í˜•ì‹ì˜ elapsedTimeì„ ë¶„(min) ë‹¨ìœ„ ì •ìˆ˜ë¡œ ë³€í™˜.
    ì˜ˆ: "45:12" â†’ 45ë¶„, "01:30:00" â†’ 90ë¶„
    """
    if isinstance(s, str):
        parts = s.split(':')
        try:
            if len(parts) == 2:
                return int(parts[0]) + int(parts[1]) // 60
            elif len(parts) == 3:
                return int(parts[0]) * 60 + int(parts[1])
        except:
            pass
    try:
        return int(float(s))
    except:
        return None


def compute_fatigue_index(row):
    """
    í”¼ë¡œë„ ê³„ì‚° ê³µì‹ (ì˜ˆì‹œ):
    - ì‹¬ë°•ìˆ˜, ì§€ì† ì‹œê°„, í˜ì´ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‹¨ìˆœ ê³„ì‚°
    - ê°’ ë²”ìœ„ëŠ” 0.0~1.0 ì‚¬ì´ ì •ê·œí™” (ì˜ˆì‹œ ê¸°ì¤€)

    ì¡°ì • í•„ìš”: ì‹¤ì œ í”¼ë“œë°± ë°ì´í„°ê°€ ìˆë‹¤ë©´ í•™ìŠµ ê¸°ë°˜ íšŒê·€ëª¨ë¸ë¡œ ëŒ€ì²´ ê°€ëŠ¥
    """
    heart = row.get('heart_rate', 0) or 0
    duration = row.get('elapsedTime', 0) or 0
    pace = row.get('pace', 0) or 0

    # í”¼ë¡œë„ = ì‹¬ë°•ìˆ˜ ì •ê·œí™” * ì‹œê°„ ì •ê·œí™” * í˜ì´ìŠ¤ ê°€ì¤‘ì¹˜
    heart_score = min(heart / 200, 1.0)
    duration_score = min(duration / 90, 1.0)
    pace_score = max(0, min((7.5 - pace) / 5, 1.0))  # ë¹ ë¥¼ìˆ˜ë¡ í”¼ë¡œ

    return round(heart_score * duration_score * pace_score, 3)


def load_runhistory_dataframe(user=None):
    queryset = RunHistory.objects.select_related('user')
    
    if user is not None:
        queryset = queryset.filter(user=user)


    df = pd.DataFrame(list(queryset.values(
        'user__email', 'dateTime', 'distanceKm', 'elapsedTime',
        'calories', 'averageSpeedKmh', 'cadenceSpm', 'route',
        'heart_rate', 'pace', 'gap_days', 'fatigue_index',
        'is_challenge', 'run_type', 'predicted_distance', 'predicted_intensity'
    )))
    df.rename(columns={"user__email": "user_email"}, inplace=True)

    # âœ… elapsedTimeì„ ìˆ«ìí˜• ë¶„(min)ìœ¼ë¡œ ë³€í™˜
    df['elapsedTime'] = df['elapsedTime'].apply(convert_elapsed_to_min)
    df['fatigue_index'] = df.apply(
    lambda row: compute_fatigue_index(row) if pd.isnull(row['fatigue_index']) else row['fatigue_index'],
    axis=1
    )
    return df






def classify_intensity(row):
    score = 0

    # ì†ë„ ì ìˆ˜ (ë¹ ë¥¼ìˆ˜ë¡ ê°•ë„ ë†’ìŒ)
    if row['pace'] <= 5.0:
        score += 2
    elif 5.0 < row['pace'] <= 6.2:
        score += 1

    # ì‹¬ë°•ìˆ˜ ì ìˆ˜
    if row['heart_rate'] >= 160:
        score += 2
    elif 145 <= row['heart_rate'] < 160:
        score += 1

    # ê±°ë¦¬ ì ìˆ˜
    if row['distanceKm'] >= 9:
        score += 2
    elif 6 <= row['distanceKm'] < 9:
        score += 1

    # ì´ì  ê¸°ë°˜ ë¶„ë¥˜
    if score >= 5:
        return 'High'
    elif score >= 3:
        return 'Medium'
    else:
        return 'Low'


# def train_and_predict():
#     df = load_runhistory_dataframe()

#     # ë¼ë²¨ ìƒì„±
#     df['intensity_label'] = df.apply(classify_intensity, axis=1)
#     df['next_distance'] = df.groupby('user_id')['distance_km'].shift(-1)
#     df['next_intensity_label'] = df.groupby('user_id')['intensity_label'].shift(-1)
#     df.dropna(subset=['next_distance', 'next_intensity_label'], inplace=True)

#     # ğŸ“Š ì‹œê°í™” (í™•ì¸ìš©)
#     sns.boxplot(data=df, x='next_intensity_label', y='pace')
#     plt.title("pace vs intensity")
#     plt.show()

#     sns.boxplot(data=df, x='next_intensity_label', y='heart_rate')
#     plt.title("heart_rate vs intensity")
#     plt.show()

#     print("\nâœ… ë¼ë²¨ ë¶„í¬:")
#     print(df['next_intensity_label'].value_counts())

#     # âš–ï¸ í´ë˜ìŠ¤ ê· í˜• ë§ì¶”ê¸° (ìµœì†Œê°’ ê¸°ì¤€)
#     min_size = min(
#         df['next_intensity_label'].value_counts()['High'],
#         df['next_intensity_label'].value_counts()['Low'],
#         df['next_intensity_label'].value_counts()['Medium']
#     )

#     df_balanced = pd.concat([
#         resample(df[df['next_intensity_label'] == lbl], replace=True, n_samples=min_size, random_state=42)
#         for lbl in ['High', 'Medium', 'Low']
#     ])


#     # ê¸°ì¡´ features, X, y ì •ì˜ ì´í›„ë¶€í„° ìˆ˜ì •
#     features = ['distance_km', 'pace', 'heart_rate', 'duration_min', 'fatigue_index', 'gap_days']
#     X = df[features]
#     y_distance = df['next_distance']
#     y_intensity = df['next_intensity_label']
#     groups = df['user_id']

#     # ğŸ¯ SMOTE ì ìš© (ê°•ë„ ë¶„ë¥˜ìš© ë°ì´í„°ë§Œ)
#     sm = SMOTE(random_state=42)
#     X_smote, y_smote = sm.fit_resample(X, y_intensity)

#     # ê±°ë¦¬ ì˜ˆì¸¡ì€ SMOTE ì—†ì´ ì›ë˜ ë°ì´í„° ì‚¬ìš©
#     X_d = X
#     y_d = y_distance

#     # ì‚¬ìš©ì IDì— ë§ì¶° ê·¸ë£¹ ì¶”ì¶œ (SMOTE ì´í›„ì—ëŠ” user_id ì •ë³´ê°€ ì‚¬ë¼ì§€ë¯€ë¡œ)
#     # ë”°ë¼ì„œ ì‚¬ìš©ì ê¸°ë°˜ ë¶„í• ì€ ì—¬ê¸°ê¹Œì§€ë§Œ ì‚¬ìš©í•˜ê³  ì´í›„ëŠ” ë¬´ì‘ìœ„ ë¶„í• ë¡œ ì²˜ë¦¬
#     gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
#     train_idx_d, test_idx_d = next(gss.split(X_d, y_d, groups=groups))

#     X_train_d, X_test_d = X_d.iloc[train_idx_d], X_d.iloc[test_idx_d]
#     y_train_d, y_test_d = y_d.iloc[train_idx_d], y_d.iloc[test_idx_d]

#     # ğŸ§  SMOTE ë°ì´í„°ëŠ” ì‚¬ìš©ì ê¸°ë°˜ ë¶„í•  ë¶ˆê°€ â†’ ëœë¤ ë¶„í•  ì‚¬ìš©
#     from sklearn.model_selection import train_test_split
#     X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(
#         X_smote, y_smote, test_size=0.2, random_state=42, stratify=y_smote
#     )

#     # ê±°ë¦¬ ì˜ˆì¸¡ ëª¨ë¸ (ê¸°ì¡´ê³¼ ë™ì¼)
#     reg_model = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)
#     reg_model.fit(X_train_d, y_train_d)

#     # ê°•ë„ ë¶„ë¥˜ ëª¨ë¸ (ê¸°ì¡´ê³¼ ë™ì¼)
#     clf_model = RandomForestClassifier(n_estimators=200, max_depth=10, class_weight='balanced', random_state=42)
#     clf_model.fit(X_train_c, y_train_c)

#     # ì €ì¥
#     os.makedirs(MODEL_DIR, exist_ok=True)
#     joblib.dump(reg_model, os.path.join(MODEL_DIR, 'global_distance_predictor.pkl'))
#     joblib.dump(clf_model, os.path.join(MODEL_DIR, 'global_intensity_classifier.pkl'))

#     # ì˜ˆì¸¡ ìƒ˜í”Œ
#     sample = X_test_d.iloc[[0]]
#     pred_distance = reg_model.predict(sample)
#     pred_intensity = clf_model.predict(sample)

#     # í‰ê°€
#     mae = mean_absolute_error(y_test_d, reg_model.predict(X_test_d))
#     acc = accuracy_score(y_test_c, clf_model.predict(X_test_c))

#     print(f"\nâœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ (SMOTE ì ìš©)")
#     print(f"ğŸ“ ê±°ë¦¬ ì˜ˆì¸¡ MAE: {mae:.2f} km")
#     print(f"ğŸ”¥ ê°•ë„ ë¶„ë¥˜ ì •í™•ë„: {acc * 100:.2f}%")
#     print(f"ğŸ¯ ì˜ˆì¸¡ ìƒ˜í”Œ:")
#     print(f"- ì˜ˆì¸¡ ê±°ë¦¬: {pred_distance[0]:.2f} km")
#     print(f"- ì˜ˆì¸¡ ê°•ë„: {pred_intensity[0]}")



def train_and_predict():
    df = load_runhistory_dataframe()

    # ë¼ë²¨ ìƒì„±
    df['intensity_label'] = df.apply(classify_intensity, axis=1)
    df['next_distance'] = df.groupby('user_email')['distanceKm'].shift(-1)  # âœ… user_email ê¸°ë°˜
    df['next_intensity_label'] = df.groupby('user_email')['intensity_label'].shift(-1)
    df.dropna(subset=['next_distance', 'next_intensity_label'], inplace=True)

    # ğŸ“Š ì‹œê°í™” (í™•ì¸ìš©)
    sns.boxplot(data=df, x='next_intensity_label', y='pace')
    plt.title("pace vs intensity")
    plt.show()

    sns.boxplot(data=df, x='next_intensity_label', y='heart_rate')
    plt.title("heart_rate vs intensity")
    plt.show()

    print("\nâœ… ë¼ë²¨ ë¶„í¬:")
    print(df['next_intensity_label'].value_counts())

    # âš–ï¸ í´ë˜ìŠ¤ ê· í˜• ë§ì¶”ê¸° (ìµœì†Œê°’ ê¸°ì¤€)
    min_size = min(
        df['next_intensity_label'].value_counts()['High'],
        df['next_intensity_label'].value_counts()['Low'],
        df['next_intensity_label'].value_counts()['Medium']
    )

    df_balanced = pd.concat([
        resample(df[df['next_intensity_label'] == lbl], replace=True, n_samples=min_size, random_state=42)
        for lbl in ['High', 'Medium', 'Low']
    ])

    # Feature ì •ì˜
    features = ['distanceKm', 'pace', 'heart_rate', 'elapsedTime', 'fatigue_index', 'gap_days']
    X = df_balanced[features]
    y_distance = df_balanced['next_distance']
    y_intensity = df_balanced['next_intensity_label']
    groups = df_balanced['user_email']  # âœ… ë³€ê²½ë¨

    # ğŸ¯ SMOTE ì ìš© (ê°•ë„ ë¶„ë¥˜ìš© ë°ì´í„°ë§Œ)
    sm = SMOTE(random_state=42)
    X_smote, y_smote = sm.fit_resample(X, y_intensity)

    # ê±°ë¦¬ ì˜ˆì¸¡ì€ SMOTE ì—†ì´ ì›ë˜ ë°ì´í„° ì‚¬ìš©
    X_d = X
    y_d = y_distance

    # ì‚¬ìš©ì(email) ê¸°ë°˜ ë¶„í•  â†’ SMOTE ì´ì „ ë°ì´í„°ì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥
    gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
    train_idx_d, test_idx_d = next(gss.split(X_d, y_d, groups=groups))

    X_train_d, X_test_d = X_d.iloc[train_idx_d], X_d.iloc[test_idx_d]
    y_train_d, y_test_d = y_d.iloc[train_idx_d], y_d.iloc[test_idx_d]

    # ğŸ§  SMOTE ì´í›„ì—ëŠ” ì‚¬ìš©ì ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ ë¬´ì‘ìœ„ ë¶„í• 
    X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(
        X_smote, y_smote, test_size=0.2, random_state=42, stratify=y_smote
    )

    # ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ
    reg_model = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)
    reg_model.fit(X_train_d, y_train_d)

    clf_model = RandomForestClassifier(n_estimators=200, max_depth=10, class_weight='balanced', random_state=42)
    clf_model.fit(X_train_c, y_train_c)

    # ëª¨ë¸ ì €ì¥
    os.makedirs(MODEL_DIR, exist_ok=True)
    joblib.dump(reg_model, os.path.join(MODEL_DIR, 'global_distance_predictor.pkl'))
    joblib.dump(clf_model, os.path.join(MODEL_DIR, 'global_intensity_classifier.pkl'))

    # í‰ê°€ ë° ì˜ˆì¸¡ ìƒ˜í”Œ
    sample = X_test_d.iloc[[0]]
    pred_distance = reg_model.predict(sample)
    pred_intensity = clf_model.predict(sample)

    mae = mean_absolute_error(y_test_d, reg_model.predict(X_test_d))
    acc = accuracy_score(y_test_c, clf_model.predict(X_test_c))

    print(f"\nâœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ (SMOTE ì ìš©)")
    print(f"ğŸ“ ê±°ë¦¬ ì˜ˆì¸¡ MAE: {mae:.2f} km")
    print(f"ğŸ”¥ ê°•ë„ ë¶„ë¥˜ ì •í™•ë„: {acc * 100:.2f}%")
    print(f"ğŸ¯ ì˜ˆì¸¡ ìƒ˜í”Œ:")
    print(f"- ì˜ˆì¸¡ ê±°ë¦¬: {pred_distance[0]:.2f} km")
    print(f"- ì˜ˆì¸¡ ê°•ë„: {pred_intensity[0]}")

if __name__ == "__main__":
    train_and_predict()
